{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau,CosineAnnealingLR\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import sys\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import (Resize, RandomCrop,VerticalFlip, HorizontalFlip, Normalize, Compose, Crop, PadIfNeeded, RandomBrightness, Rotate)\n",
    "from albumentations.pytorch import ToTensor\n",
    "import cv2\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provider(\n",
    "    image_path,\n",
    "    phase,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    batch_size=8,\n",
    "    num_workers=0,\n",
    "):\n",
    "    assert phase in (\"train\", \"val\", \"test\")\n",
    "\n",
    "    image_list = glob(os.path.join(image_path, \"*\"))\n",
    "    print(\"total images: {}\".format(len(image_list)))\n",
    "\n",
    "    index = range(len(image_list))\n",
    "\n",
    "    dataset = CatDataset(index, image_list, phase=phase)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=False,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "def get_transforms(phase, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    list_transforms = []\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            Resize(256, 256),\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "class CatDataset(Dataset):\n",
    "    def __init__(self, idx, image_list, phase=\"train\"):\n",
    "        assert phase in ( \"test\")\n",
    "        self.idx = idx\n",
    "        self.image_list = image_list\n",
    "        self.phase = phase\n",
    "\n",
    "        self.transform = get_transforms(phase)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        real_idx = self.idx[index]\n",
    "        image_path = self.image_list[real_idx]\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        augmented = self.transform(image=image)\n",
    "\n",
    "        return augmented[\"image\"], image_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''This class takes care of training and validation of our model'''\n",
    "    def __init__(self, model):\n",
    "        self.num_workers = 0\n",
    "        self.batch_size = {\"test\":8}\n",
    "        self.accumulation_steps = 32 // self.batch_size['test']\n",
    "        self.phases = [\"test\"]\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        self.net = model\n",
    "\n",
    "        self.net = self.net.to(self.device)\n",
    "        cudnn.benchmark = True\n",
    "        self.dataloaders = {\n",
    "            phase: provider(\n",
    "                image_path=IMAGEPATH,\n",
    "                phase=phase,\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=self.batch_size[phase],\n",
    "                num_workers=self.num_workers,\n",
    "            )                                                   \n",
    "            for phase in self.phases\n",
    "        }\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        \n",
    "    def forward(self, images):\n",
    "        images = images.to(self.device)\n",
    "        outputs = self.net(images)\n",
    "        \n",
    "        return  outputs\n",
    "\n",
    "\n",
    "    def iterate(self, phase):\n",
    "        start = time.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Starting epoch: 0 | phase: {phase} | ⏰: {start}\")\n",
    "        self.net.train(phase == \"train\")\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        for batch in tqdm(dataloader):\n",
    "            images, pathes = batch\n",
    "            with torch.no_grad():\n",
    "                outputs = self.forward(images)\n",
    "            \n",
    "            batch_preds = torch.sigmoid(outputs)  \n",
    "            # 预测结果以图片的形式存在输入图片的相同路径下，后面带有 label 后缀\n",
    "            # 预测结果的分辨率统一为 256*256，若需恢复原分辨率需要调用albumentations 中的 Resize\n",
    "            for i in range(batch_preds.shape[0]):\n",
    "                numpy_output = batch_preds[i].squeeze(0).detach().cpu().numpy()\n",
    "                r = np.where(numpy_output > 0.5, 255, 0).astype(\"uint8\")\n",
    "                cv2.imwrite(os.path.splitext(pathes[i])[0]+\"_label.jpg\", r)\n",
    "            \n",
    "                    \n",
    "    def start(self):\n",
    "        self.iterate(\"test\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELPATH = \"\"  # 模型路径\n",
    "IMAGEPATH = r\".\\cat\\200\" # 图片路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total images: 16\n",
      "Starting epoch: 0 | phase: test | ⏰: 20:35:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\cat\\200\\cat-6.jpg\n",
      "('.\\\\cat\\\\200\\\\cat-6', '.jpg')\n",
      ".\\cat\\200\\cat-6_label.jpg\n",
      "('.\\\\cat\\\\200\\\\cat-6_label', '.jpg')\n",
      ".\\cat\\200\\cat_0.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_0', '.jpg')\n",
      ".\\cat\\200\\cat_0_label.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_0_label', '.jpg')\n",
      ".\\cat\\200\\cat_1.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_1', '.jpg')\n",
      ".\\cat\\200\\cat_1_label.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_1_label', '.jpg')\n",
      ".\\cat\\200\\cat_2.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_2', '.jpg')\n",
      ".\\cat\\200\\cat_2_label.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_2_label', '.jpg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:02<00:02,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\cat\\200\\cat_3.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_3', '.jpg')\n",
      ".\\cat\\200\\cat_3_label.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_3_label', '.jpg')\n",
      ".\\cat\\200\\cat_4.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_4', '.jpg')\n",
      ".\\cat\\200\\cat_4_label.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_4_label', '.jpg')\n",
      ".\\cat\\200\\cat_5.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_5', '.jpg')\n",
      ".\\cat\\200\\cat_5_label.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_5_label', '.jpg')\n",
      ".\\cat\\200\\cat_7.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_7', '.jpg')\n",
      ".\\cat\\200\\cat_7_label.jpg\n",
      "('.\\\\cat\\\\200\\\\cat_7_label', '.jpg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(MODELPATH):\n",
    "        \n",
    "    model = smp.Unet('resnet50', classes=1, activation=None)\n",
    "    state = torch.load(MODELPATH, map_location=lambda storage, loc: storage)\n",
    "\n",
    "    model.load_state_dict(state[\"state_dict\"])\n",
    "else:\n",
    "    model = smp.Unet('resnet50', classes=1, activation=None)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "model_trainer = Trainer(model)\n",
    "model_trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
